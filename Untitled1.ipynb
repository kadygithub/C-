{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kadygithub/C-/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyU1f49pJb4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDZFEjh_K3OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Helper libraries\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage\n",
        "from six.moves import urllib\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "\n",
        "class Data_Mnist:\n",
        "  def __init__(self):\n",
        "    self.SOURCE = 'http://yann.lecun.com/exdb/mnist/'\n",
        "    self.DATA_DIR= \"data\"\n",
        "    self.IMAGE_SIZE = 28\n",
        "    self.CHANNELS = 1\n",
        "    self.INTENSITY = 255\n",
        "    self.LABELS = 10\n",
        "    self.filepath=\"\"\n",
        "    # number of the validation  data images.\n",
        "    self.SIZE_VALIDATION= 5000  \n",
        "\n",
        "# import data\n",
        "  def import_data(self,filename):\n",
        "      #check the DATA_DIR, if data dose not exist,make directory and then download data!\n",
        "      if not tf.gfile.Exists(self.DATA_DIR):\n",
        "          tf.gfile.MakeDirs(self.DATA_DIR)\n",
        "      filepath = os.path.join(self.DATA_DIR, filename)\n",
        "      if not tf.gfile.Exists(filepath):\n",
        "          filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
        "          print('data downloaded')\n",
        "      \n",
        "      return filepath\n",
        "  def pull_images(self,filename, num_images):\n",
        "    \"\"\"First we pull the images into a 4D tensor [image_index, y, x, channels] \n",
        "      then flatten out the later 3 dimensions[image_index, y*x*channels]\n",
        "    \"\"\"\n",
        "   \n",
        "    print('Extracting', filename)\n",
        "    with gzip.open(filename) as f:\n",
        "        k=f.read(16)\n",
        "        \n",
        "        \n",
        "        b = f.read(self.IMAGE_SIZE * self.IMAGE_SIZE * num_images * self.CHANNELS)\n",
        "        # to use the memory buffer of the data directly\n",
        "        data = numpy.frombuffer(b, dtype=numpy.uint8).astype(numpy.float32)\n",
        "        #rescaling values of pixels : [0,255] --> [-1,1]\n",
        "        data = (data - (self.INTENSITY / 2.0)) / self.INTENSITY\n",
        "        print(data.shape,\"shape\",type(data))\n",
        "        data = data.reshape(num_images, self.IMAGE_SIZE, self.IMAGE_SIZE, self.CHANNELS)\n",
        "        \n",
        "        # we don't need this layered information (num_images, 28, 28, 1), \n",
        "        #so we just flatten out the later 3 dimensions (num_images, 784) \n",
        "        data = numpy.reshape(data, [num_images, -1])\n",
        "        \n",
        "    return data\n",
        "  \n",
        "  def pull_labels(self,filename,num_images):\n",
        "      # the labels are extracted into a vector\"\"\"\n",
        "      with gzip.open(filename) as f:\n",
        "          f.read(8)\n",
        "          b = f.read(1 * num_images)\n",
        "          labels = numpy.frombuffer(b, dtype=numpy.uint8).astype(numpy.int64)\n",
        "          num_labels = len(labels)\n",
        "          encoding= numpy.zeros((num_labels,self.LABELS))\n",
        "          encoding[numpy.arange(num_labels),labels] = 1\n",
        "          encoding = numpy.reshape(encoding, [-1, self.LABELS])\n",
        "          \n",
        "      return encoding\n",
        "  def Produce_data(self,data_augmentation_Flag=False):\n",
        "      # Download data\n",
        "      train_data = self.import_data('train-images-idx3-ubyte.gz')\n",
        "      train_labels =self.import_data('train-labels-idx1-ubyte.gz')\n",
        "      test_data = self.import_data('t10k-images-idx3-ubyte.gz')\n",
        "      test_labels =self.import_data('t10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "      # pull images and labels into numpy tensors\n",
        "      train_data = self.pull_images(train_data,60000)\n",
        "      train_labels = self.pull_labels(train_labels, 60000)\n",
        "      test_data = self.pull_images(test_data, 10000)\n",
        "      test_labels = self.pull_labels(test_labels, 10000)\n",
        "\n",
        "      # Set validation data from training data\n",
        "      validation_data = train_data[:self.SIZE_VALIDATION, :]\n",
        "      validation_labels = train_labels[:self.SIZE_VALIDATION,:]\n",
        "      train_data = train_data[self.SIZE_VALIDATION:, :]\n",
        "      train_labels = train_labels[self.SIZE_VALIDATION:,:]\n",
        "\n",
        "      #  data_augmentation\n",
        "      if data_augmentation_Flag:\n",
        "          train_total_data = expend_training_data(train_data, train_labels)\n",
        "      else:\n",
        "          \n",
        "          train_total_data = numpy.concatenate((train_data, train_labels), axis=1)\n",
        "\n",
        "      train_size = train_total_data.shape[0]\n",
        "\n",
        "      return train_total_data, train_size, validation_data, validation_labels, test_data, test_labels\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZssG7XOPQqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}